{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UYscuWgX2-Gx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from easy_transformer import EasyTransformer, EasyTransformerConfig\n",
        "import easy_transformer\n",
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2ffUhwWCQ8X-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moving model to device:  cuda\n",
            "Moving model to device:  cuda\n"
          ]
        }
      ],
      "source": [
        "vocab_size = 500\n",
        "sequence_length = 10\n",
        "batch_size = 64\n",
        "\n",
        "tiny_cfg = EasyTransformerConfig(\n",
        "    d_model=32,\n",
        "    d_head=8,\n",
        "    n_heads=4,\n",
        "    d_mlp=32,\n",
        "    n_layers=2,\n",
        "    n_ctx=100,\n",
        "    act_fn=\"solu_ln\",\n",
        "    d_vocab=vocab_size,\n",
        "    normalization_type=\"LN\",\n",
        "    seed=0,\n",
        ")\n",
        "tiny_model = EasyTransformer(tiny_cfg).to(device)\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UHb_5W6wRhJo"
      },
      "outputs": [],
      "source": [
        "start_token = 0\n",
        "sep_token = 1\n",
        "ignore_token = 2\n",
        "num_special_tokens = 3\n",
        "def get_copy_instance(batch_size,seq_size, vocab_size):\n",
        "  seqs = torch.randint(num_special_tokens, vocab_size, (batch_size, seq_size)).to(device)\n",
        "\n",
        "  input1 = torch.cat([\n",
        "      torch.ones((batch_size,1),device=device)*sep_token,\n",
        "      seqs,\n",
        "  ],dim=1)\n",
        "\n",
        "  input2 = torch.cat([\n",
        "      torch.ones((batch_size,1),device=device)*sep_token,\n",
        "      seqs,\n",
        "  ],dim=1)[:,:-1]\n",
        "\n",
        "  output1 = torch.cat([\n",
        "      torch.ones((batch_size,1+seq_size),device=device)*ignore_token,\n",
        "  ],dim=1)\n",
        "  output2 = torch.cat([\n",
        "      seqs,\n",
        "      torch.ones((batch_size,1),device=device)*sep_token,\n",
        "  ],dim=1)[:,:-1]\n",
        "\n",
        "  perm = torch.randperm(seq_size,device=device)\n",
        "  input = torch.cat([input1,input2[:,perm]],dim=1)\n",
        "  output = torch.cat([output1,output2[:,perm]],dim=1)\n",
        "\n",
        "  return input.long(),output.long()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IS-D65e0MU4D"
      },
      "outputs": [],
      "source": [
        "eval_inputs, eval_outputs = get_copy_instance(1000, 20, tiny_model.cfg.d_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RXnuyzmvUzl-"
      },
      "outputs": [],
      "source": [
        "def get_loss(model, inputs, outputs):\n",
        "    inputs = inputs.to(device)\n",
        "    outputs = outputs.to(device)\n",
        "    \n",
        "    output_logits = model(inputs, return_type=\"logits\")\n",
        "\n",
        "    seq_len = inputs.shape[1]\n",
        "\n",
        "    loss = cross_entropy_loss(\n",
        "        output_logits[:,seq_len//2+1:].reshape((-1,vocab_size)),\n",
        "        outputs[:,seq_len//2+1:].reshape((-1,)))\n",
        "    \n",
        "    return loss\n",
        "\n",
        "def evaluate_model(model, batch_size, print_output, number_to_print=0):\n",
        "    vocab_size = model.cfg.d_vocab\n",
        "    inputs,outputs = get_copy_instance(batch_size,random.randint(5,30),vocab_size)\n",
        "\n",
        "    loss = get_loss(model,inputs,outputs)\n",
        "\n",
        "    if print_output:\n",
        "      eval_loss = get_loss(model,eval_inputs, eval_outputs)\n",
        "      print(eval_loss.item())\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "roYpPSYrU2Jt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before training\n",
            "6.514003753662109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 4/100001 [00:00<51:21, 32.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.514003753662109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 331/100001 [00:08<41:21, 40.17it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [10], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m      7\u001b[0m loss_history\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[0;32m----> 8\u001b[0m tiny_optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m      9\u001b[0m tiny_optimizer\u001b[39m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m/local/scratch-3/fwe21/miniconda3/envs/torch/lib/python3.9/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
            "File \u001b[0;32m/local/scratch-3/fwe21/miniconda3/envs/torch/lib/python3.9/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
            "File \u001b[0;32m/local/scratch-3/fwe21/miniconda3/envs/torch/lib/python3.9/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     adam(params_with_grad,\n\u001b[1;32m    235\u001b[0m          grads,\n\u001b[1;32m    236\u001b[0m          exp_avgs,\n\u001b[1;32m    237\u001b[0m          exp_avg_sqs,\n\u001b[1;32m    238\u001b[0m          max_exp_avg_sqs,\n\u001b[1;32m    239\u001b[0m          state_steps,\n\u001b[1;32m    240\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    241\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    242\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    243\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    244\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    245\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    246\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    247\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    248\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    249\u001b[0m          differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    250\u001b[0m          fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    251\u001b[0m          grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    252\u001b[0m          found_inf\u001b[39m=\u001b[39;49mfound_inf)\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
            "File \u001b[0;32m/local/scratch-3/fwe21/miniconda3/envs/torch/lib/python3.9/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m func(params,\n\u001b[1;32m    301\u001b[0m      grads,\n\u001b[1;32m    302\u001b[0m      exp_avgs,\n\u001b[1;32m    303\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    304\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    305\u001b[0m      state_steps,\n\u001b[1;32m    306\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    307\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    308\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    309\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    310\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    311\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    312\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    313\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    314\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    315\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    316\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
            "File \u001b[0;32m/local/scratch-3/fwe21/miniconda3/envs/torch/lib/python3.9/site-packages/torch/optim/adam.py:364\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    363\u001b[0m exp_avg\u001b[39m.\u001b[39mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1)\n\u001b[0;32m--> 364\u001b[0m exp_avg_sq\u001b[39m.\u001b[39;49mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad\u001b[39m.\u001b[39mconj(), value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[1;32m    366\u001b[0m \u001b[39mif\u001b[39;00m capturable \u001b[39mor\u001b[39;00m differentiable:\n\u001b[1;32m    367\u001b[0m     step \u001b[39m=\u001b[39m step_t\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "loss_history = []\n",
        "print('before training')\n",
        "loss = evaluate_model(tiny_model, batch_size=3000, print_output=True)\n",
        "for epoch in tqdm.tqdm(range(100001)):\n",
        "    loss = evaluate_model(tiny_model, batch_size=batch_size, print_output=epoch % 100 == 0, number_to_print=0)\n",
        "    loss.backward()\n",
        "    loss_history.append(loss.item())\n",
        "    tiny_optimizer.step()\n",
        "    tiny_optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "y7xdqMOniNF8",
        "outputId": "b06a5494-f26d-4097-9261-6640cd090100"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff3503dd3d0>]"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(loss_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "ZPyzJHURUQCi"
      },
      "outputs": [],
      "source": [
        "import pysvelte\n",
        "def show_attention_pattern_for_input(model, input,output):\n",
        "    model_cache={}\n",
        "    model.cache_all(model_cache) # remove_batch_dim=True\n",
        "    model(input)\n",
        "    model.reset_hooks()\n",
        "    tokens = [str(x) for x in input[0].tolist()]\n",
        "    print('tokens', tokens, 'len(tokens)', len(tokens))\n",
        "    pysvelte.AttentionMulti(tokens=tokens, attention=model_cache['blocks.0.attn.hook_attn'][0].permute(1, 2, 0)).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "fPkqYc2SRYnP"
      },
      "outputs": [],
      "source": [
        "inputs,outputs = get_copy_instance(3,10,100)\n",
        "\n",
        "output_logits = tiny_model(inputs, return_type=\"logits\")\n",
        "predictions = output_logits.argmax(dim=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnCyZiyuYtRk",
        "outputId": "6a2fca33-094a-41fd-dfed-fd4adfd53686"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1 67 48 79 44 58 73 68 19 35 17 58  1 68 19 48 44 35 73 67 79]\n",
            " [ 2  2  2  2  2  2  2  2  2  2  2 73 67 19 35 79 58 17 68 48 44]\n",
            " [ 2  2  2  2  2  2  2  2  2  2  2 73 67 19 35 79 58 17 68 48 44]]\n",
            "tokens ['1', '67', '48', '79', '44', '58', '73', '68', '19', '35', '17', '58', '1', '68', '19', '48', '44', '35', '73', '67', '79'] len(tokens) 21\n",
            "pysvelte components appear to be unbuilt or stale\n",
            "Running npm install...\n"
          ]
        }
      ],
      "source": [
        "print(np.array([\n",
        "    inputs[0].tolist(),\n",
        "    outputs[0].tolist(),\n",
        "    predictions[0].tolist()\n",
        "  ]))\n",
        "\n",
        "show_attention_pattern_for_input(tiny_model,inputs,outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afOPHA3bX90h",
        "outputId": "980773b7-a24d-4f00-a33b-dcdf6b8b77b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  2,   2,   2,   2,   2,   2,   6,   7, 363]], device='cuda:0')"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tiny_model(torch.tensor([[1,3,4,5,6,7,5,6,6]]), return_type=\"logits\").argmax(dim=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThdzZUdlU40l"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('torch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "ab29bdd578247210423fe399e48aecd0ef8b6f86b36785b7520d6025e6beafbf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
